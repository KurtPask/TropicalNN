{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from absl import app, flags\n",
    "from easydict import EasyDict\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import AveragePooling2D, Conv2D, MaxPooling2D, Dense, Flatten\n",
    "\n",
    "from custom_layers.tropical_layers import TropEmbedMaxMinLogits, ChangeSignLayer, TropEmbedMaxMin\n",
    "from functions.models import CH_ReluConv3Layer, CH_ReLU_ResNet50, CH_Trop_ResNet50, CH_TropConv3LayerLogits, CH_MaxoutConv3Layer, CH_MaxOut_ResNet50\n",
    "from functions.load_data import load_CIFAR_data\n",
    "\n",
    "from cleverhans.tf2.attacks.projected_gradient_descent import projected_gradient_descent\n",
    "from cleverhans.tf2.attacks.fast_gradient_method import fast_gradient_method\n",
    "#from cleverhans.tf2.attacks.carlini_wagner_l2 import carlini_wagner_l2\n",
    "from edited_carlini_wagner_l2 import carlini_wagner_l2\n",
    "#from cleverhans.tf2.attacks.spsa import spsa\n",
    "from edited_spsa import spsa\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "def ld_cifar10():\n",
    "    \"\"\"Load training and test data.\"\"\"\n",
    "\n",
    "    def convert_types(image, label):\n",
    "        image = tf.cast(image, tf.float32)\n",
    "        image /= 127.5\n",
    "        image -= 1.0\n",
    "        return image, label\n",
    "\n",
    "    dataset, info = tfds.load(\"cifar10\", with_info=True, as_supervised=True)\n",
    "\n",
    "    def augment_mirror(x):\n",
    "        return tf.image.random_flip_left_right(x)\n",
    "\n",
    "    def augment_shift(x, w=4):\n",
    "        y = tf.pad(x, [[w] * 2, [w] * 2, [0] * 2], mode=\"REFLECT\")\n",
    "        return tf.image.random_crop(y, tf.shape(x))\n",
    "\n",
    "    cifar10_train, cifar10_test = dataset[\"train\"], dataset[\"test\"]\n",
    "    # Augmentation helps a lot in CIFAR10\n",
    "    cifar10_train = cifar10_train.map(\n",
    "        lambda x, y: (augment_mirror(augment_shift(x)), y)\n",
    "    )\n",
    "    cifar10_train = cifar10_train.map(convert_types).shuffle(10000).batch(128)\n",
    "    cifar10_test = cifar10_test.map(convert_types).batch(128)\n",
    "\n",
    "    return EasyDict(train=cifar10_train, test=cifar10_test)\n",
    "\n",
    "\n",
    "def main(_):\n",
    "    # Load training and test data\n",
    "    data = ld_cifar10()\n",
    "    #model = CH_TropConv3LayerLogits(num_classes=10)\n",
    "    #model = CH_ReLU_ResNet50(num_classes=10)\n",
    "    #model = CH_Trop_ResNet50(num_classes=10)\n",
    "    #model = CH_MaxoutConv3Layer(num_classes=10)\n",
    "    #model = CH_ReluConv3Layer(num_classes=10)\n",
    "    #CH_MaxOut_ResNet50(num_classes=10), \n",
    "    models = [CH_ReluConv3Layer(num_classes=10)]\n",
    "\n",
    "    for model in models:\n",
    "        loss_object = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "        optimizer = tf.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "        # Metrics to track the different accuracies.\n",
    "        train_loss = tf.metrics.Mean(name=\"train_loss\")\n",
    "        train_acc = tf.metrics.SparseCategoricalAccuracy()\n",
    "        test_acc_clean = tf.metrics.SparseCategoricalAccuracy()\n",
    "        test_acc_fgsm = tf.metrics.SparseCategoricalAccuracy()\n",
    "        test_acc_pgd_inf = tf.metrics.SparseCategoricalAccuracy()\n",
    "        test_acc_pgd_2 = tf.metrics.SparseCategoricalAccuracy()\n",
    "        test_acc_cw = tf.metrics.SparseCategoricalAccuracy()\n",
    "        test_acc_spsa = tf.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "        @tf.function\n",
    "        def train_step(x, y):\n",
    "            with tf.GradientTape() as tape:\n",
    "                predictions = model(x)\n",
    "                loss = loss_object(y, predictions)\n",
    "            gradients = tape.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "            train_loss(loss)\n",
    "            train_acc(y, predictions)\n",
    "\n",
    "        # Train model with adversarial training\n",
    "        for epoch in range(FLAGS.nb_epochs):\n",
    "            #train_acc = tf.metrics.SparseCategoricalAccuracy()\n",
    "            # keras like display of progress\n",
    "            progress_bar_train = tf.keras.utils.Progbar(50000)\n",
    "            print(f\"--epoch {epoch}--\")\n",
    "            for (x, y) in data.train:\n",
    "                if FLAGS.adv_train:\n",
    "                    # Replace clean example with adversarial example for adversarial training\n",
    "                    #x = projected_gradient_descent(model, x, FLAGS.eps, 0.01, 40, np.inf)\n",
    "                    x = fast_gradient_method(model, x, FLAGS.eps, np.inf)\n",
    "                train_step(x, y)\n",
    "                progress_bar_train.add(x.shape[0], values=[(\"loss\", train_loss.result()), (\"acc\", train_acc.result())])\n",
    "        model.summary()\n",
    "        #model.save(f'CH_MaxoutConv3Layer_{FLAGS.eps}_{FLAGS.nb_epochs}_{FLAGS.adv_train}', save_format='tf')\n",
    "\n",
    "        # Evaluate on clean and adversarial data\n",
    "        progress_bar_test = tf.keras.utils.Progbar(10000)\n",
    "\n",
    "        for x, y in data.test:\n",
    "            # -- clean --\n",
    "            y_pred = model(x)\n",
    "            test_acc_clean(y, y_pred)\n",
    "\n",
    "            # -- fast gradient sign method --\n",
    "            x_fgm = fast_gradient_method(model, x, FLAGS.eps, np.inf)\n",
    "            y_pred_fgm = model(x_fgm)\n",
    "            test_acc_fgsm(y, y_pred_fgm)\n",
    "\n",
    "            # -- l_inf || projected gradient descent --\n",
    "            x_pgd_inf = projected_gradient_descent(model, x, FLAGS.eps, 0.01, 40, np.inf)\n",
    "            y_pred_pgd_inf = model(x_pgd_inf)\n",
    "            test_acc_pgd_inf(y, y_pred_pgd_inf)\n",
    "            '''\n",
    "            # -- l_2 || projected gradient descent --\n",
    "            x_pgd_2 = projected_gradient_descent(model, x, FLAGS.eps, 0.01, 40, 2)\n",
    "            y_pred_pgd_2 = model(x_pgd_2)\n",
    "            test_acc_pgd_2(y, y_pred_pgd_2)\n",
    "            '''\n",
    "            # -- spsa --\n",
    "            #x_spsa_list = []\n",
    "            y_pred_spsa_list = []\n",
    "\n",
    "            for i in range(x.shape[0]):\n",
    "                x_single = x[i:i+1]\n",
    "                x_spsa_single = spsa(model, x=x_single, y=y[i], eps=FLAGS.eps, \n",
    "                                nb_iter=2, learning_rate=0.01, delta=0.01, \n",
    "                                spsa_samples=12, spsa_iters=1,\n",
    "                                clip_min=-1, clip_max=1)\n",
    "                #x_spsa_list.append(x_spsa_single)\n",
    "                y_pred_spsa_single = model(x_spsa_single)\n",
    "                y_pred_spsa_list.append(y_pred_spsa_single)\n",
    "            #x_spsa = tf.concat(x_spsa_list, axis=0)\n",
    "            y_pred_spsa = tf.concat(y_pred_spsa_list, axis=0)\n",
    "            test_acc_spsa(y, y_pred_spsa)\n",
    "\n",
    "            \n",
    "            # -- carlini wagner --\n",
    "            x_cw = carlini_wagner_l2(model, x, \n",
    "                                    clip_min=-1.0, \n",
    "                                    max_iterations=10, \n",
    "                                    binary_search_steps=2,\n",
    "                                    confidence=0,\n",
    "                                    initial_const=1e-2,\n",
    "                                    learning_rate=1e-2)\n",
    "            y_pred_cw = model(x_cw)\n",
    "            test_acc_cw(y, y_pred_cw)\n",
    "            \n",
    "            progress_bar_test.add(x.shape[0])\n",
    "\n",
    "        print(\"test acc on clean examples (%): {:.3f}\".format(test_acc_clean.result() * 100))\n",
    "        print(\"test acc on FGM adversarial examples (%): {:.3f}\".format(test_acc_fgsm.result() * 100))\n",
    "        print(\"test acc on l_inf PGD adversarial examples (%): {:.3f}\".format(test_acc_pgd_inf.result() * 100))\n",
    "        #print(\"test acc on l_2 PGD adversarial examples (%): {:.3f}\".format(test_acc_pgd_2.result() * 100))\n",
    "        print(\"test acc on Carlini Wagner adversarial examples (%): {:.3f}\".format(test_acc_cw.result() * 100))\n",
    "        print(\"test acc on SPSA adversarial examples (%): {:.3f}\".format(test_acc_spsa.result() * 100))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    flags.DEFINE_integer(\"nb_epochs\", 1, \"Number of epochs.\")\n",
    "    flags.DEFINE_float(\"eps\", 0.05, \"Total epsilon for FGM and PGD attacks.\")\n",
    "    flags.DEFINE_bool(\"adv_train\", False, \"Use adversarial training (on PGD adversarial examples).\")\n",
    "    app.run(main)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
