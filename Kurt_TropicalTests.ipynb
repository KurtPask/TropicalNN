{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.load_data import load_CIFAR_data, load_Google_Digit_Data, load_MNIST_data, shuffle_data\n",
    "from functions.attacks import attackTestSet, attackTestSetBatch\n",
    "from functions.models import simple_relu_model, simple_tropical_model\n",
    "from custom_layers.initializers import BimodalBinaryInitializer, BimodalNormalInitializer, Triangular\n",
    "from tensorflow.keras import losses, initializers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick test to see if adding ReLU trained weights before fitting might be a good initializer: \n",
    "#### nothing major found, but could come back to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_layers.tropLayers import TropEmbedMaxMin\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "pre_trained_weights1 = [model_objects[0].layers[0].get_weights()[0].T]\n",
    "model = Sequential([TropEmbedMaxMin(100, x_train.shape[1], initializer_w = initializers.random_normal, lam=0.01),\n",
    "                    Dense(1, activation='sigmoid',  kernel_initializer=initializers.random_normal)])\n",
    "model.get_layer('trop_embed_max_min_10').set_weights(pre_trained_weights1)\n",
    "model.compile(optimizer=Adam(0.1),loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=10, verbose=1)\n",
    "model.evaluate(x_test, y_test)\n",
    "\n",
    "plt.hist(pre_trained_weights1[0].flatten(), bins = 1000, alpha=0.2)\n",
    "plt.hist(model.layers[0].get_weights()[0].flatten(), bins = 1000, alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIFAR 2 class, accuracy look as change layer size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = load_CIFAR_data(desired_classes=[7, 8])\n",
    "\n",
    "for i in range(1, 200, 2):\n",
    "    print(f'================\\n\\t{i}\\n================')\n",
    "    for j in range(5):\n",
    "        x_train, x_test, y_train, y_test = shuffle_data(x_train, x_test, y_train, y_test)\n",
    "        data = []\n",
    "        built_model = buildTropicalModel(x_train, y_train,  first_layer_size = i,  verbose = 1, lam=0.025)\n",
    "        pre_loss, pre_acc = built_model.evaluate(x_test, y_test) \n",
    "        with open('CIFAR_layer_size_test.csv', 'a', newline='') as csvfile:\n",
    "            csvwriter = csv.writer(csvfile)\n",
    "            csvwriter.writerow([i,pre_loss, pre_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scat_size = 10\n",
    "bin_num = 784\n",
    "hist_wid = 20\n",
    "hist_hei = 8\n",
    "data = pd.read_csv(\"CIFAR_layer_size_test.csv\")\n",
    "rowNum = data.shape[0]\n",
    "i_avg = data.groupby('i').mean().reset_index()\n",
    "print(i_avg)\n",
    "\n",
    "plt.figure(figsize=(hist_wid,hist_hei))\n",
    "plt.boxplot([data['accuracy'][data['i'] == i] for i in data['i'].unique()])\n",
    "plt.xlabel('layer size')\n",
    "plt.ylabel('loss')\n",
    "plt.title(f'loss from varying layer size for {rowNum} tests')\n",
    "plt.grid(True)\n",
    "plt.show() \n",
    "\n",
    "plt.scatter(data['i'], data['accuracy'], s=scat_size)\n",
    "plt.xlabel('layer size')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title(f'accuracy from varying layer size for {rowNum} tests')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(data['i'], data['loss'], s=scat_size)\n",
    "plt.xlabel('layer size')\n",
    "plt.ylabel('loss')\n",
    "plt.title(f'loss from varying layer size for {rowNum} tests')\n",
    "plt.grid(True)\n",
    "plt.show() \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIFAR 2 class test, ensembling multiple 1 layer models to test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = load_CIFAR_data(desired_classes=[7, 8])\n",
    "model_objects = []\n",
    "for i in range(5):\n",
    "    print(f'================\\n\\t{i}\\n================')\n",
    "    x_train, x_test, y_train, y_test = shuffle_data(x_train, x_test, y_train, y_test)\n",
    "    data = []\n",
    "    built_model = buildTropicalModel(x_train, y_train,  first_layer_size = 20,  verbose = 1, lam=0.025)\n",
    "    pre_loss, pre_acc = built_model.evaluate(x_test, y_test) \n",
    "    model_objects.append(built_model)\n",
    "    with open('CIFAR_1_neuron_layer_test.csv', 'a', newline='') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        csvwriter.writerow([i,pre_loss, pre_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = shuffle_data(x_train, x_test, y_train, y_test)\n",
    "num_models = len(model_objects)\n",
    "\n",
    "model_predictions = [model_objects[i].predict(x_test) for i in range(num_models)]\n",
    "ensemble_sum = np.sum(model_predictions, axis=0)\n",
    "\n",
    "ensemble_class_indices = np.array(ensemble_sum>(num_models/2)).astype(int).reshape(-1)\n",
    "accuracy = np.mean(y_test == ensemble_class_indices)\n",
    "print(f'Ensemble Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(model_predictions[0]>0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIFAR 2 class, PGD attack, different Initializer test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = losses.BinaryCrossentropy()\n",
    "x_train, x_test, y_train, y_test = load_CIFAR_data(desired_classes=[7, 8])\n",
    "tests = [0,0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.175, 0.2]\n",
    "for i in tests:\n",
    "    print(f'================\\n\\t{i}\\n================')\n",
    "    data = []\n",
    "    built_model = buildTropicalModel(x_train, y_train, num_epochs = 10, first_layer_size = 100, initializer_w=initializers.RandomNormal(mean=0.5, stddev=0.005, seed=0), verbose = 1,\n",
    "                        second_layer_size = 1,second_layer_activation = 'sigmoid', training_loss = 'binary_crossentropy', lam=i)\n",
    "    x_test_att = attackTestSetBatch(built_model, x_test, y_test, loss_object, str(i))\n",
    "    pre_loss, pre_acc = built_model.evaluate(x_test, y_test)\n",
    "    post_loss, post_acc = built_model.evaluate(x_test_att, y_test)\n",
    "    data = [i,pre_loss, pre_acc, post_loss, post_acc]\n",
    "    with open('CIFAR_lambda_test2.csv', 'a', newline='') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        csvwriter.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scat_size = 20\n",
    "bin_num = 784\n",
    "hist_wid = 10\n",
    "hist_hei = 8\n",
    "data = pd.read_csv(\"CIFAR_lambda_test.csv\")\n",
    "rowNum = data.shape[0]\n",
    "\n",
    "#lambda,pre_loss,pre_acc,post_loss,post_acc\n",
    "\n",
    "data[\"loss_diff\"] = data['post_loss'] - data['pre_loss']\n",
    "data[\"acc_diff\"] = data['post_acc'] - data['pre_acc']\n",
    "\n",
    "columns = [\"pre_loss\"]#, \"post_loss\"]\n",
    "settings = [\"Pre-attack test Loss\", \"Post-attack test Loss\"]\n",
    "\n",
    "plt.figure(figsize=(hist_wid,hist_hei))\n",
    "for i in range(len(columns)):\n",
    "    plt.scatter(data['lambda'], data[columns[i]], label=settings[i], s=scat_size)\n",
    "plt.xticks([i/100 for i in range(101)])\n",
    "#plt.yticks([i/20 for i in range(21)])\n",
    "plt.xlabel('Lambda')\n",
    "plt.xlim(-0.005, 0.205)\n",
    "plt.ylim(-1, 30)\n",
    "plt.ylabel('Loss')\n",
    "plt.title(f'Loss from varying lambda for {rowNum} tests')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "'''\n",
    "plt.figure(figsize=(hist_wid,hist_hei))\n",
    "for i in model_objects:\n",
    "    plt.hist(i.layers[0].get_weights()[0].flatten(), bins=bin_num, alpha=0.3, label='l')\n",
    "plt.xlabel('Initial Accuracy on Test Set')\n",
    "plt.ylabel('Count')\n",
    "plt.title(f'Initial Accuracy for {rowNum} tests')\n",
    "plt.ylim(0, 7000)\n",
    "#plt.legend()\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "x_train, x_test, y_train, y_test = load_CIFAR_data(desired_classes=[7, 8])\n",
    "t_model1 = buildTropicalModel(x_train, y_train, verbose=1, initializer_w=BimodalNormalInitializer(stddev=1,high=5.5, low=-4.5), lam = 0)\n",
    "weights1 = t_model1.layers[0].get_weights()[0].flatten()\n",
    "\n",
    "t_model2 = buildTropicalModel(x_train, y_train,  verbose=1,initializer_w=BimodalNormalInitializer(stddev=1,high=5.5, low=-4.5), lam = 0.1)\n",
    "weights2 = t_model2.layers[0].get_weights()[0].flatten()\n",
    "\n",
    "t_model3 = buildTropicalModel(x_train, y_train, verbose=1, initializer_w=BimodalNormalInitializer(stddev=1,high=5.5, low=-4.5), lam = 0.5)\n",
    "weights3 = t_model3.layers[0].get_weights()[0].flatten()\n",
    "\n",
    "x_train, x_test, y_train, y_test = load_CIFAR_data(desired_classes=[7, 8])\n",
    "t_model1 = buildTropicalModel(x_train, y_train, verbose=1, initializer_w=initializers.RandomNormal(0.5, 0.005, seed=0), lam = 0)\n",
    "weights1 = t_model1.layers[0].get_weights()[0].flatten()\n",
    "\n",
    "t_model2 = buildTropicalModel(x_train, y_train,  verbose=1,initializer_w=initializers.RandomNormal(0.5, 0.005, seed=0), lam = 0.1)\n",
    "weights2 = t_model2.layers[0].get_weights()[0].flatten()\n",
    "\n",
    "t_model3 = buildTropicalModel(x_train, y_train, verbose=1, initializer_w=initializers.RandomNormal(0.5, 0.005, seed=0), lam = 0.5)\n",
    "weights3 = t_model3.layers[0].get_weights()[0].flatten()\n",
    "\n",
    "t_model1.evaluate(x_test, y_test)\n",
    "t_model2.evaluate(x_test, y_test)\n",
    "t_model3.evaluate(x_test, y_test)\n",
    "'''\n",
    "plt.hist(weights1, bins = 784, alpha = 0.3, label='lambda=0')\n",
    "plt.hist(weights2, bins = 784, alpha = 0.3, label='lambda=0.1')\n",
    "plt.hist(weights3, bins = 784, alpha = 0.3, label='lambda=0.5')\n",
    "plt.ylim(0,1000)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializers Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 100\n",
    "loss_object = losses.BinaryCrossentropy()\n",
    "x_train, x_test, y_train, y_test = load_CIFAR_data()\n",
    "tests = [(buildReLuModel, initializers.RandomNormal(mean=0.5, stddev=1., seed=0), \"ReLU\"),\n",
    "         (buildTropicalModel, BimodalBinaryInitializer(high=5.5, low=-4.5), \"Tropical -4.5 or 5.5\"),\n",
    "         (buildTropicalModel, BimodalNormalInitializer(stddev=1,high=5.5, low=-4.5), \"Tropical ~N(-4.5,1) or ~N(5.5,1)\"),\n",
    "         (buildTropicalModel, Triangular(left=0,mode=0.5, right=1), \"Tropical ~Triangular(0, 0.5, 1)\"),\n",
    "         (buildTropicalModel, initializers.Constant(0.5), \"Tropical vector of all 0.5\"),\n",
    "         (buildTropicalModel, initializers.RandomNormal(0.5, 0.005, seed=0), \"Tropical ~N(0.5,0.005)\"),\n",
    "         (buildTropicalModel, initializers.random_normal, \"Tropical random_normal\")]\n",
    "\n",
    "for i in range(iterations):\n",
    "    print(f'================\\n\\t{i}\\n================')\n",
    "    x_train, x_test, y_train, y_test = shuffle_data(x_train, x_test, y_train, y_test) \n",
    "    data = []\n",
    "    for model, intializer_w, name in tests:\n",
    "        built_model = model(x_train, y_train, initializer_w=intializer_w, verbose = 1)\n",
    "        x_test_att = attackTestSetBatch(built_model, x_test, y_test, loss_object, name)\n",
    "        pre_loss, pre_acc = built_model.evaluate(x_test, y_test)\n",
    "        post_loss, post_acc = built_model.evaluate(x_test_att, y_test)\n",
    "        data.extend([pre_loss, pre_acc, post_loss, post_acc])\n",
    "    with open('Initializer_Test.csv', 'a', newline='') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        csvwriter.writerow(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['relu', 'trop_bin', 'trop_nor', 'trop_tri', 'trop_constant', 'trop_rand_small', 'trop_rand_default']\n",
    "types = ['_pre_loss', '_pre_acc', '_post_loss', '_post_acc', '_loss_diff', '_acc_diff']\n",
    "col_headers = [i+j for i in names for j in types]\n",
    "pre_loss_headers = [i for i in col_headers if types[0] in i]\n",
    "pre_acc_headers = [i for i in col_headers if types[1] in i]\n",
    "post_loss_headers = [i for i in col_headers if types[2] in i]\n",
    "post_acc_headers = [i for i in col_headers if types[3] in i]\n",
    "loss_diff_headers = [i for i in col_headers if types[4] in i]\n",
    "acc_diff_headers = [i for i in col_headers if types[5] in i]\n",
    "settings = [tup[2] for tup in tests]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scat_size = 12\n",
    "bin_num = 40\n",
    "hist_wid = 9\n",
    "hist_hei = 6\n",
    "round_dec = 4\n",
    "data = pd.read_csv(\"Initializer_Test.csv\")\n",
    "rowNum = data.shape[0]\n",
    "\n",
    "for i in range(len(settings)):\n",
    "    data[loss_diff_headers[i]] = data[post_loss_headers[i]] - data[pre_loss_headers[i]]\n",
    "    data[acc_diff_headers[i]] = data[post_acc_headers[i]] - data[pre_acc_headers[i]]\n",
    "\n",
    "plt.figure(figsize=(hist_wid,hist_hei))\n",
    "plt.boxplot(data[pre_loss_headers[1:]], labels=settings[1:])\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel('Initialization Setting')\n",
    "plt.xlabel('Initial Loss on Test Set')\n",
    "plt.title(f'Initial Loss for {rowNum} tests')\n",
    "plt.grid(axis = 'y')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(hist_wid,hist_hei))\n",
    "plt.boxplot(data[pre_acc_headers[1:]], labels=settings[1:])\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel('Initialization Setting')\n",
    "plt.xlabel('Initial Accuracy on Test Set')\n",
    "plt.title(f'Initial Accuracy for {rowNum} tests')\n",
    "plt.grid(axis = 'y')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(hist_wid,hist_hei))\n",
    "plt.boxplot(data[loss_diff_headers[1:]], labels=settings[1:])\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel('Initialization Setting')\n",
    "plt.xlabel('Loss Increase After PGD Attack on Test Set')\n",
    "plt.title(f'Loss Increases for {rowNum} tests')\n",
    "plt.grid(axis = 'y')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(hist_wid,hist_hei))\n",
    "plt.boxplot(data[acc_diff_headers[1:]], labels=settings[1:])\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel('Initialization Setting')\n",
    "plt.xlabel('Accuracy Decrease After PGD Attack on Test Set')\n",
    "plt.title(f'Accuracy Decreases for {rowNum} tests')\n",
    "plt.grid(axis = 'y')\n",
    "plt.show()\n",
    "\n",
    "columns1 = pre_loss_headers\n",
    "columns2 = post_loss_headers\n",
    "plt.figure(figsize=(hist_wid,hist_hei))\n",
    "for i in range(len(columns)):\n",
    "    plt.scatter(data[columns1[i]], data[columns2[i]], s=scat_size, label=settings[i])\n",
    "plt.xlabel('Pre-Attack Loss')\n",
    "plt.ylabel('Post-Attack Loss')\n",
    "plt.title(f'Loss for {rowNum} tests')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "columns1 = pre_acc_headers\n",
    "columns2 = post_acc_headers\n",
    "plt.figure(figsize=(hist_wid,hist_hei))\n",
    "for i in range(len(columns)):\n",
    "    plt.scatter(data[columns1[i]], data[columns2[i]], s=scat_size, label=settings[i])\n",
    "plt.xlabel('Pre-Attack Accuracy')\n",
    "plt.ylabel('Post-Attack Accuracy')\n",
    "plt.title(f'Accuracy for {rowNum} tests')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = load_CIFAR_data()\n",
    "tests = [(buildReLuModel, initializers.RandomNormal(mean=0.5, stddev=1., seed=0), \"ReLU\"),\n",
    "         (buildTropicalModel, BimodalBinaryInitializer(high=5.5, low=-4.5), \"Tropical -4.5 or 5.5\"),\n",
    "         (buildTropicalModel, BimodalNormalInitializer(stddev=1,high=5.5, low=-4.5), \"Tropical ~N(-4.5,1) or ~N(5.5,1)\"),\n",
    "         (buildTropicalModel, Triangular(left=0,mode=0.5, right=1), \"Tropical ~Triangular(0, 0.5, 1)\"),\n",
    "         (buildTropicalModel, initializers.Constant(0.5), \"Tropical vector of all 0.5\"),\n",
    "         (buildTropicalModel, initializers.RandomNormal(0.5, 0.005, seed=0), \"Tropical ~N(0.5,0.005)\"),\n",
    "         (buildTropicalModel, initializers.random_normal, \"Tropical random_normal\")]\n",
    "\n",
    "model_objects = []\n",
    "for model, intializer_w, name in tests:\n",
    "    built_model = model(x_train, y_train, initializer_w=intializer_w, verbose = 1)\n",
    "    model_objects.append(built_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = [tup[2] for tup in tests]\n",
    "for i in range(len(settings)):\n",
    "    t1 = model_objects[i].layers[0].get_weights()[0].flatten()\n",
    "    t1_m = np.mean(t1)\n",
    "    t1_s = np.std(t1)\n",
    "    plt.figure(figsize=(8,7))\n",
    "    plt.hist(t1, alpha=0.4,  bins = 392)\n",
    "    plt.title(f\"{settings[i]} mean={t1_m: .3f}, std={t1_s: .3f}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "t1 = model_objects[1].layers[0].get_weights()[0].flatten()\n",
    "t2 = model_objects[2].layers[0].get_weights()[0].flatten()\n",
    "\n",
    "t1_m = np.mean(t1)\n",
    "t1_s = np.std(t1)\n",
    "t2_m = np.mean(t2)\n",
    "t2_s = np.std(t2)\n",
    "\n",
    "binnies = 784\n",
    "\n",
    "plt.figure(figsize=(8,7))\n",
    "plt.hist(t1, alpha=0.4, label=f\"Tropical -4.5 or 5.5 mean={t1_m: .3f}, std={t1_s: .3f}\",  bins = binnies)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,7))\n",
    "plt.hist(t1, alpha=0.4, label=f\"Tropical -4.5 or 5.5 mean={t1_m: .3f}, std={t1_s: .3f}\",  bins = binnies)\n",
    "plt.legend()\n",
    "plt.ylim(0, 5000)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,7))\n",
    "initializer = BimodalNormalInitializer(stddev=1,high=5.5, low=-4.5) \n",
    "weights_tensor = initializer(shape=(100, 3072), dtype=tf.float32)\n",
    "plt.hist(weights_tensor.numpy().flatten(), alpha=0.4,bins=binnies, label='Initial Weights ~N(-4.5,1) or ~N(5.5,1)')\n",
    "plt.hist(t2, alpha=0.4, label=f\"Post-Training ~N(-4.5,1) or ~N(5.5,1) mean={t2_m: .3f}, std={t2_s: .3f}\", bins = binnies)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST, all numbers PGD test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 50\n",
    "loss_object = losses.CategoricalCrossentropy()\n",
    "x_train, x_test, y_train, y_test = load_MNIST_data(desired_classes=[i for i in range(10)])\n",
    "#tests = [(buildReLuModel, initializers.RandomNormal(mean=0.5, stddev=1., seed=0), \"ReLU\"),\n",
    "#         (buildTropicalModel, BimodalBinaryInitializer(high=4, low=-3), \"Tropical -3 or 4\"),\n",
    "tests = [(buildTropicalModel, BimodalNormalInitializer(stddev=1,high=4, low=-3), \"Tropical ~N(-3,1) or ~N(4,1)\")]\n",
    "#         (buildTropicalModel, initializers.RandomNormal(0.5, 0.005, seed=0), \"Tropical ~N(0.5,0.005)\")]\n",
    "\n",
    "model_objects = []\n",
    "for i in range(iterations):\n",
    "    print(f'================\\n\\t{i}\\n================')\n",
    "    x_train, x_test, y_train, y_test = shuffle_data(x_train, x_test, y_train, y_test) \n",
    "    data = []\n",
    "    \n",
    "    for model, intializer_w, name in tests:\n",
    "        built_model = model(x_train, y_train, first_layer_size = 100, initializer_w=intializer_w, verbose = 1,\n",
    "                            second_layer_size = 10,second_layer_activation = 'softmax', training_loss = 'categorical_crossentropy')\n",
    "        #x_test_att = attackTestSetBatch(built_model, x_test, y_test, loss_object, name)\n",
    "        #pre_loss, pre_acc = built_model.evaluate(x_test, y_test)\n",
    "        #post_loss, post_acc = built_model.evaluate(x_test_att, y_test)\n",
    "        #data.extend([pre_loss, pre_acc, post_loss, post_acc])\n",
    "        model_objects.append(built_model)\n",
    "    #with open('bimodalTest.csv', 'a', newline='') as csvfile:\n",
    "        #csvwriter = csv.writer(csvfile)\n",
    "        #csvwriter.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "save_dir = 'saved_models'  # Change this to your desired directory\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "for i, model in enumerate(model_objects):\n",
    "    model_name = f'model_{i}.h5'  # Adjust the naming scheme as needed\n",
    "    model_path = os.path.join(save_dir, model_name)\n",
    "    tf.keras.models.save_model(model, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scat_size = 12\n",
    "bin_num = 30\n",
    "hist_wid = 14\n",
    "hist_hei = 12\n",
    "data = pd.read_csv(\"bimodalTest.csv\")\n",
    "rowNum = data.shape[0]\n",
    "\n",
    "data[\"relu_loss_diff\"] = data['relu_post_loss'] - data['relu_pre_loss']\n",
    "data[\"relu_acc_diff\"] = data['relu_post_acc'] - data['relu_pre_acc']\n",
    "\n",
    "data[\"trop_loss_diff1\"] = data['trop_post_loss1'] - data['trop_pre_loss1']\n",
    "data[\"trop_acc_diff1\"] = data['trop_post_acc1'] - data['trop_pre_acc1']\n",
    "\n",
    "data[\"trop_loss_diff2\"] = data['trop_post_loss2'] - data['trop_pre_loss2']\n",
    "data[\"trop_acc_diff2\"] = data['trop_post_acc2'] - data['trop_pre_acc2']\n",
    "\n",
    "data[\"trop_loss_diff3\"] = data['trop_post_loss3'] - data['trop_pre_loss3']\n",
    "data[\"trop_acc_diff3\"] = data['trop_post_acc3'] - data['trop_pre_acc3']\n",
    "\n",
    "columns = [\"relu_pre_loss\", \"trop_pre_loss1\", \"trop_pre_loss2\", \"trop_pre_loss3\"]\n",
    "settings = [\"ReLU\", \"Tropical -3 or 4\", \"Tropical ~N(-3,1) or ~N(4,1)\", \"Tropical ~N(0.5,0.005)\"]\n",
    "\n",
    "plt.figure(figsize=(hist_wid,hist_hei))\n",
    "for i in range(len(columns)):\n",
    "    plt.hist(np.array(data[columns[i]]), bins=bin_num, alpha=0.5, label=f'{settings[i]} Loss. Mean={round(data[columns[i]].mean(),2)}, Std={round(data[columns[i]].std(),2)}')\n",
    "plt.xlabel('Initial Loss on Test Set')\n",
    "plt.ylabel('Count')\n",
    "plt.title(f'Initial Loss for {rowNum} tests')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "columns = [\"relu_pre_acc\", \"trop_pre_acc1\", \"trop_pre_acc2\", \"trop_pre_acc3\"]\n",
    "plt.figure(figsize=(hist_wid,hist_hei))\n",
    "for i in range(len(columns)):\n",
    "    plt.hist(np.array(data[columns[i]]), bins=bin_num, alpha=0.5, label=f'{settings[i]} Accuracy. Mean={round(data[columns[i]].mean(),2)}, Std={round(data[columns[i]].std(),2)}')\n",
    "plt.xlabel('Initial Accuracy on Test Set')\n",
    "plt.ylabel('Count')\n",
    "plt.title(f'Initial Accuracy for {rowNum} tests')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "columns = [\"relu_loss_diff\", \"trop_loss_diff1\", \"trop_loss_diff2\", \"trop_loss_diff3\"]\n",
    "plt.figure(figsize=(hist_wid,hist_hei))\n",
    "for i in range(len(columns)):\n",
    "    plt.hist(np.array(data[columns[i]]), bins=bin_num, alpha=0.5, label=f'{settings[i]} Loss Increase. Mean={round(data[columns[i]].mean(),2)}, Std={round(data[columns[i]].std(),2)}')\n",
    "plt.xlabel('Loss Increase After PGD Attack on Test Set')\n",
    "plt.ylabel('Count')\n",
    "plt.title(f'Loss Increases for {rowNum} tests')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "columns = [\"relu_acc_diff\", \"trop_acc_diff1\", \"trop_acc_diff2\", \"trop_acc_diff3\"]\n",
    "plt.figure(figsize=(hist_wid,hist_hei))\n",
    "for i in range(len(columns)):\n",
    "    plt.hist(np.array(data[columns[i]]), bins=bin_num, alpha=0.5, label=f'{settings[i]} Accuracy Increase. Mean={round(data[columns[i]].mean(),2)}, Std={round(data[columns[i]].std(),2)}')\n",
    "plt.xlabel('Accuracy Decrease After PGD Attack on Test Set')\n",
    "plt.ylabel('Count')\n",
    "plt.title(f'Accuracy Decreases for {rowNum} tests')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "columns1 = [\"relu_pre_loss\", \"trop_pre_loss1\", \"trop_pre_loss2\", \"trop_pre_loss3\"]\n",
    "columns2 = [\"relu_post_loss\", \"trop_post_loss1\", \"trop_post_loss2\", \"trop_post_loss3\"]\n",
    "plt.figure(figsize=(hist_wid,hist_hei))\n",
    "for i in range(len(columns)):\n",
    "    plt.scatter(data[columns1[i]], data[columns2[i]], s=scat_size, label=settings[i])\n",
    "plt.xlabel('Pre-Attack Loss')\n",
    "plt.ylabel('Post-Attack Loss')\n",
    "plt.title(f'Loss for {rowNum} tests')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "columns1 = [\"relu_pre_acc\", \"trop_pre_acc1\", \"trop_pre_acc2\", \"trop_pre_acc3\"]\n",
    "columns2 = [\"relu_post_acc\", \"trop_post_acc1\", \"trop_post_acc2\", \"trop_post_acc3\"]\n",
    "plt.figure(figsize=(hist_wid,hist_hei))\n",
    "for i in range(len(columns)):\n",
    "    plt.scatter(data[columns1[i]], data[columns2[i]], s=scat_size, label=settings[i])\n",
    "plt.xlabel('Pre-Attack Accuracy')\n",
    "plt.ylabel('Post-Attack Accuracy')\n",
    "plt.title(f'Accuracy for {rowNum} tests')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_images = x_test.reshape(-1, 28, 28)\n",
    "relu_images = relu_x_test_att.reshape(-1, 28, 28)\n",
    "trop_images = trop_x_test_att1.reshape(-1, 28, 28)\n",
    "\n",
    "def show_images(images, num_images=5):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(1, num_images, i + 1)\n",
    "        plt.imshow(images[i+5], cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(normal_images, num_images=5)\n",
    "show_images(relu_images, num_images=5)\n",
    "show_images(trop_images, num_images=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_predictions = [model_objects[i].predict(x_test) for i in range(len(model_objects))]\n",
    "ensemble_sum = np.sum(model_predictions, axis=0)\n",
    "true_class_indices = np.argmax(y_test, axis=1)\n",
    "ensemble_class_indices = np.argmax(ensemble_sum, axis=1)\n",
    "accuracy = np.mean(true_class_indices == ensemble_class_indices)\n",
    "print(f'Ensemble Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    model_objects[i].evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reluModel = model_objects[0]\n",
    "weights = reluModel.layers[0].get_weights()[0].flatten()\n",
    "biases = reluModel.layers[0].get_weights()[1].flatten()\n",
    "print(weights.shape)\n",
    "plt.hist(weights, bins=int(784), alpha=0.5)\n",
    "#plt.hist(biases, bins=int(784), alpha=0.5)\n",
    "plt.ylim(0, 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = model_objects[1].layers[0].get_weights()[0].flatten()\n",
    "t2 = model_objects[2].layers[0].get_weights()[0].flatten()\n",
    "t3 = model_objects[3].layers[0].get_weights()[0].flatten()\n",
    "\n",
    "t1_m = np.mean(t1)\n",
    "t1_s = np.std(t1)\n",
    "t2_m = np.mean(t2)\n",
    "t2_s = np.std(t2)\n",
    "t3_m = np.mean(t3)\n",
    "t3_s = np.std(t3)\n",
    "\n",
    "binnies = 784\n",
    "\n",
    "plt.figure(figsize=(8,7))\n",
    "plt.hist(t1, alpha=0.4, label=f\"bernoulli mean={t1_m: .3f}, std={t1_s: .3f}\",  bins = binnies)\n",
    "plt.hist(t2, alpha=0.4, label=f\"bernoulli normals mean={t2_m: .3f}, std={t2_s: .3f}\", bins = binnies)\n",
    "plt.hist(t3, alpha=0.4, label=f\"random_normal mean={t3_m: .3f}, std={t3_s: .3f}\", bins = binnies)\n",
    "#plt.hist(weights, alpha=0.4, label=\"ReLU\", density=True, bins = binnies)\n",
    "plt.ylim(0, 600)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = Triangular(left=0,mode=0.5, right=1)  # You can set the seed for reproducibility\n",
    "weights_tensor = initializer(shape=(100, 784), dtype=tf.float32)\n",
    "plt.hist(weights_tensor.numpy().flatten(), bins=784)\n",
    "plt.hist(t3, bins=784, alpha=0.4, label=f\"random_normal {round(np.mean(t3),3)}, {np.sum(t3 < 0)}, {np.sum(t3 > 0)}\")\n",
    "plt.ylim(0, 600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = BimodalNormalInitializer(high=4, low=-3, seed=42)  # You can set the seed for reproducibility\n",
    "weights_tensor = initializer(shape=(500, 784), dtype=tf.float32)\n",
    "#weights_tensor.numpy()\n",
    "plt.hist(weights_tensor.numpy().flatten(), bins = 784,alpha =0.4)\n",
    "plt.hist(built_model.layers[0].get_weights()[0].flatten(), bins=int(784), alpha=0.4)\n",
    "plt.ylim(0, 3000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PGD Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 500 #aribitrary\n",
    "loss_object = losses.BinaryCrossentropy()\n",
    "x_train, x_test, y_train, y_test = load_MNIST_data(desired_classes=[2, 8])\n",
    "\n",
    "for i in range(iterations):\n",
    "    print(f'================\\n\\t{i}\\n================')\n",
    "    x_train, x_test, y_train, y_test = shuffle_data(x_train, x_test, y_train, y_test) \n",
    "\n",
    "    reluModel = buildReLuModel(x_train, y_train, verbose=1)\n",
    "    #relu_x_test_att = attackTestSet(reluModel, x_test, y_test, loss_object, \"ReLu\")\n",
    "    relu_pre_loss, relu_pre_acc = reluModel.evaluate(x_test, y_test)\n",
    "    #relu_post_loss, relu_post_acc = reluModel.evaluate(relu_x_test_att, y_test)\n",
    "\n",
    "    tropModel1 = buildTropicalModel(x_train, y_train, verbose=1)\n",
    "    #trop_x_test_att1 = attackTestSet(tropModel1, x_test, y_test, loss_object, \"Tropical\")\n",
    "    trop_pre_loss1, trop_pre_acc1 = tropModel1.evaluate(x_test, y_test)\n",
    "    #trop_post_loss1, trop_post_acc1 = tropModel1.evaluate(trop_x_test_att1, y_test)\n",
    "\n",
    "    # - write to csv - \n",
    "    data = [relu_pre_loss, relu_pre_acc, relu_post_loss, relu_post_acc,trop_pre_loss1, trop_pre_acc1, trop_post_loss1, trop_post_acc1]\n",
    "    with open('output4.csv', 'a', newline='') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        csvwriter.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scat_size = 8\n",
    "bin_num = 4\n",
    "hist_wid = 8\n",
    "hist_hei = 6\n",
    "data = pd.read_csv(\"output3.csv\")\n",
    "rowNum = data.shape[0]\n",
    "\n",
    "data[\"relu_loss_diff\"] = data['relu_post_loss'] - data['relu_pre_loss']\n",
    "data[\"trop_loss_diff1\"] = data['trop_post_loss1'] - data['trop_pre_loss1']\n",
    "data[\"relu_acc_diff\"] = data['relu_post_acc'] - data['relu_pre_acc']\n",
    "data[\"trop_acc_diff1\"] = data['trop_post_acc1'] - data['trop_pre_acc1']\n",
    "\n",
    "\n",
    "plt.figure(figsize=(hist_wid,hist_hei))\n",
    "plt.hist(np.array(data[\"relu_pre_loss\"]), bins=bin_num, alpha=0.5, label=f'ReLu Loss. Mean={round(data[\"relu_pre_loss\"].mean(),2)}, Std={round(data[\"relu_pre_loss\"].std(),2)}')\n",
    "plt.hist(np.array(data[\"trop_pre_loss1\"]), bins=bin_num, alpha=0.5, label=f'Tropical (initial_w = random_normal) Loss. Mean={round(data[\"trop_pre_loss1\"].mean(),2)}, Std={round(data[\"trop_pre_loss1\"].std(),2)}')\n",
    "plt.xlabel('Initial Loss on Test Set')\n",
    "plt.ylabel('Count')\n",
    "plt.title(f'Initial Loss for {rowNum} tests')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(hist_wid,hist_hei))\n",
    "plt.hist(np.array(data[\"relu_pre_acc\"]), bins=bin_num, alpha=0.5, label=f'ReLu Accuracy. Mean={round(data[\"relu_pre_acc\"].mean(),2)}, Std={round(data[\"relu_pre_acc\"].std(),2)}')\n",
    "plt.hist(np.array(data[\"trop_pre_acc1\"]), bins=bin_num, alpha=0.5, label=f'Tropical (initial_w = random_normal) Accuracy. Mean={round(data[\"trop_pre_acc1\"].mean(),2)}, Std={round(data[\"trop_pre_acc1\"].std(),2)}')\n",
    "plt.xlabel('Initial Accuracy on Test Set')\n",
    "plt.ylabel('Count')\n",
    "plt.title(f'Initial Accuracy for {rowNum} tests')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(hist_wid,hist_hei))\n",
    "plt.hist(np.array(data[\"relu_loss_diff\"]), bins=bin_num, alpha=0.5, label=f'ReLU Loss Increase. Mean={round(data[\"relu_loss_diff\"].mean(),2)}, Std={round(data[\"relu_loss_diff\"].std(),2)}')\n",
    "plt.hist(np.array(data[\"trop_loss_diff1\"]), bins=bin_num, alpha=0.5, label=f'Tropical (initial_w = random_normal) Loss Increase. Mean={round(data[\"trop_loss_diff1\"].mean(),2)}, Std={round(data[\"trop_loss_diff1\"].std(),2)}')\n",
    "plt.xlabel('Loss Increase After PGD Attack on Test Set')\n",
    "plt.ylabel('Count')\n",
    "plt.title(f'Loss Increases for {rowNum} tests')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(hist_wid,hist_hei))\n",
    "plt.hist(np.array(data[\"relu_acc_diff\"]), bins=bin_num, alpha=0.5, label=f'ReLU Accuracy Decrease. Mean={round(data[\"relu_acc_diff\"].mean(),2)}, Std={round(data[\"relu_acc_diff\"].std(),2)}')\n",
    "plt.hist(np.array(data[\"trop_acc_diff1\"]), bins=bin_num, alpha=0.5, label=f'Tropical (initial_w = random_normal) Accuracy Decrease. Mean={round(data[\"trop_acc_diff1\"].mean(),2)}, Std={round(data[\"trop_acc_diff1\"].std(),2)}')\n",
    "plt.xlabel('Accuracy Decrease After PGD Attack on Test Set')\n",
    "plt.ylabel('Count')\n",
    "plt.title(f'Accuracy Decreases for {rowNum} tests')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(hist_wid,hist_hei))\n",
    "plt.scatter(data['relu_pre_loss'], data['relu_post_loss'], s=6, label=f'ReLU')\n",
    "plt.scatter(data['trop_pre_loss1'], data['trop_post_loss1'], s=scat_size, label=f'Tropical (initial_w = random_normal)')\n",
    "plt.xlabel('Pre-Attack Loss')\n",
    "plt.ylabel('Post-Attack Loss')\n",
    "plt.title(f'Loss for {rowNum} tests')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(hist_wid,hist_hei))\n",
    "plt.scatter(data['relu_pre_acc'], data['relu_post_acc'], s=6, label=f'ReLU')\n",
    "plt.scatter(data['trop_pre_acc1'], data['trop_post_acc1'], s=scat_size, label=f'Tropical (initial_w = random_normal)')\n",
    "plt.xlabel('Pre-Attack Accuracy')\n",
    "plt.ylabel('Post-Attack Accuracy')\n",
    "plt.title(f'Accuracy for {rowNum} tests')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
